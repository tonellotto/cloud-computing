{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hadoop Installation and Testing\n",
    "\n",
    "> **WARNING: Be careful, the execution of this notebook can compromise your virtual machines. Do not execute any cell twice: please start from the very first cell if you have problems.**\n",
    "\n",
    "> **This notebook requires password-less SSH from the machine IT WILL BE EXECUTED ON to the machines in your cluster.**\n",
    "\n",
    "> **This notebook automatically works on Linux machines only. Windows users must configure the machines by hand.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load commands from `commands.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ssh(host, *command):\n",
    "    \"\"\"\n",
    "    :param host: ip address\n",
    "    :type f: string\n",
    "    :param command: command to execute\n",
    "    :type command: string\n",
    "\n",
    "    Execute with SSH the commands on host as the 'hadoop' user, displaying information\n",
    "    \"\"\"\n",
    "    print('===== \\x1b[31m' + 'Started on ' + host + '\\x1b[0m =====')\n",
    "    for cmd in command:\n",
    "        print(cmd)\n",
    "        !ssh hadoop@{host} {cmd}\n",
    "    print('===== \\x1b[31m' + 'Completed on ' + host + '\\x1b[0m =====')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally Hadoop can be run in three modes.\n",
    "\n",
    "1. **Standalone (or local) mode**: There are no daemons used in this mode. Hadoop uses the local file system as a substitute for HDFS file system. The jobs will run as if there is 1 mapper and 1 reducer.\n",
    "2. **Pseudo-distributed mode**: All the daemons run on a single machine and this setting mimics the behavior of a cluster. All the daemons run on your machine locally using the HDFS protocol. There can be multiple mappers and reducers.\n",
    "3. **Fully-distributed mode**: This is how Hadoop runs on a real cluster.\n",
    "\n",
    "In these notes we will describe how to set up an [Hadoop 3](https://hadoop.apache.org) installation to work with.\n",
    "We will set up a *fully-distributed cluster* on your assigned virtual machines.\n",
    "\n",
    "The core of Hadoop is composed by two main subsystem:\n",
    "\n",
    "* the **Hadoop Distributed File System** (HDFS), responsible for the distributed data management\n",
    "* the **Yet Another Resource Negotiator** (YARN), responsible for the distributed code execution\n",
    "\n",
    "Both subsystems are implemented according to the **master-workers** architecture.\n",
    "\n",
    "![Master-workers Architecture](ms1.jpg)\n",
    "\n",
    "Both HDFS and YARN have their own terminology for master and worker nodes.\n",
    "\n",
    "|    | Master         | Worker      |\n",
    "|:--:|:--------------:|:-----------:|\n",
    "|HDFS| NameNode       | DataNode    |\n",
    "|YARN| ResouceManager | NodeManager |\n",
    "\n",
    "![Master-workers Architecture](ms2.jpg)\n",
    "\n",
    "While the masters of HDFS and YARN can, in principle, be located on different machines, we will install the HDFS and YARN masters on a single machine, and install the HDFS and YARN workers on all machines (*including the machine hosting the master*).\n",
    "\n",
    "This notebook contains the steps necessary to set up and configure correctly Hadoop on our virtual machines.\n",
    "In particular:\n",
    "\n",
    "1. We will [download and install](#download) Hadoop on all our virtual machines.\n",
    "2. We will [configure](#namenode) a virtual machine to host the HDFS and YARN masters and workers.\n",
    "3. We will [configure](#datanode) the remaining virtual machines to host the HDFS and YARN workers.\n",
    "4. We will [test](#test) your newly install Hadoop cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prerequisites <a name=\"prereq\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.** Populate the following dictionary with the IP addresses (as keys) and the hostnames (as values) of all your virtual machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T21:55:11.986338Z",
     "start_time": "2020-04-07T21:55:11.980489Z"
    }
   },
   "outputs": [],
   "source": [
    "VMS = {'172.16.3.79': 'datanode1',\n",
    "       '172.16.3.80': 'datanode2', \n",
    "       '172.16.3.81': 'namenode'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** Populate the following variable with the IP address of the virtual machine with the namenode role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T21:54:14.685117Z",
     "start_time": "2020-04-07T21:54:14.673997Z"
    }
   },
   "outputs": [],
   "source": [
    "NAMENODE_IP = '172.16.3.81'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** Populate the following variable with the IP address of the remaining virtual machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMAINING_IPS = [\n",
    "    '172.16.3.79',\n",
    "    '172.16.3.80'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and install Hadoop <a name=\"download\"/>\n",
    "---\n",
    "**a.** Download [hadoop-3.1.3.tar.gz](https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/hadoop-3.1.3.tar.gz) in your home folder on your virtual machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T19:44:28.207459Z",
     "start_time": "2020-04-07T19:43:47.090004Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for host in VMS:\n",
    "    run_ssh(host, commands.WGET_CMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** Decompress the Hadoop package you can use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T21:55:22.045210Z",
     "start_time": "2020-04-07T21:55:14.894132Z"
    }
   },
   "outputs": [],
   "source": [
    "for host in VMS:\n",
    "    run_ssh(host, commands.TAR_CMD, commands.RM_CMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** There are environment settings that will be used by Hadoop. The following lines myst be appended to your `/home/hadoop/.bashrc` file **on each machine**:\n",
    "\n",
    "```bash\n",
    "export HADOOP_HOME=/opt/hadoop\n",
    "export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n",
    "export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native:$LD_LIBRARY_PATH\n",
    "export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop\n",
    "export HDFS_NAMENODE_USER=hadoop\n",
    "export HDFS_DATANODE_USER=hadoop\n",
    "export HDFS_SECONDARYNAMENODE_USER=hadoop\n",
    "export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n",
    "export HADOOP_MAPRED_HOME=$HADOOP_HOME\n",
    "export HADOOP_COMMON_HOME=$HADOOP_HOME\n",
    "export HADOOP_HDFS_HOME=$HADOOP_HOME\n",
    "export YARN_HOME=$HADOOP_HOME\n",
    "export HADOOP_LOG_DIR=$HADOOP_HOME/logs\n",
    "```\n",
    "\n",
    "The following commands append the correct environment variables to your `/home/hadoop/.bashrc` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T21:55:32.077891Z",
     "start_time": "2020-04-07T21:55:28.999693Z"
    }
   },
   "outputs": [],
   "source": [
    "for host in VMS:\n",
    "    !ssh hadoop@{host} \"sed -i '1,10 s/^/#/' ~/.bashrc\"\n",
    "    !ssh hadoop@{host} 'printf \"%s\\n\" {commands.get_bashrc()} >> ~/.bashrc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.** The following commands check Hadoop installation (you should see no errors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T21:55:37.983835Z",
     "start_time": "2020-04-07T21:55:33.556465Z"
    }
   },
   "outputs": [],
   "source": [
    "for host in VMS:\n",
    "    run_ssh(host, 'hadoop version')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure the `hadoop-namenode` machine <a name=\"namenode\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.** Update the `core-site.xml` file located at `/opt/hadoop/etc/hadoop/` to define the name node URI on this machine.\n",
    "The file must contain the following lines.\n",
    "```xml\n",
    "<configuration>\n",
    "  <property>\n",
    "    <name>fs.defaultFS</name>\n",
    "    <value>hdfs://hadoop-namenode:9820/</value>\n",
    "  </property>\n",
    "</configuration>\n",
    "```\n",
    "The following command updates the file automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T22:07:53.169774Z",
     "start_time": "2020-04-07T22:07:52.007599Z"
    }
   },
   "outputs": [],
   "source": [
    "!ssh hadoop@{NAMENODE_IP} 'printf \"%s\\n\" {commands.get_namenode_core_site(VMS[NAMENODE_IP])} > /opt/hadoop/etc/hadoop/core-site.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** Update the `hdfs-site.xml` file located at `/opt/hadoop/etc/hadoop/` to define the path on the local filesystem where the name node stores the namespace and transactions logs persistently and to configure the HDFS subsystem.\n",
    "The file must contain the following lines.\n",
    "```xml\n",
    "<configuration>\n",
    "  <property>\n",
    "    <name>dfs.namenode.name.dir</name>\n",
    "    <value>file:///opt/hdfs/namenode</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>dfs.datanode.data.dir</name>\n",
    "    <value>file:///opt/hdfs/datanode</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>dfs.replication</name>\n",
    "    <value>2</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>dfs.permissions</name>\n",
    "    <value>false</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>dfs.datanode.use.datanode.hostname</name>\n",
    "    <value>false</value>\n",
    "  </property>\n",
    "</configuration>\n",
    "```\n",
    "The following command updates the file automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T22:10:07.811788Z",
     "start_time": "2020-04-07T22:10:03.228836Z"
    }
   },
   "outputs": [],
   "source": [
    "!ssh hadoop@{NAMENODE_IP} 'printf \"%s\\n\" {commands.get_namenode_hdfs_site()} > /opt/hadoop/etc/hadoop/hdfs-site.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** Update the `yarn-site.xml` file located at `/opt/hadoop/etc/hadoop` to configure the YARN subsystem.\n",
    "The file must contain the following lines.\n",
    "\n",
    "```xml\n",
    "<configuration>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.aux-services</name>\n",
    "    <value>mapreduce_shuffle</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.resourcemanager.hostname</name>\n",
    "    <value>{hadoop_namenode}</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>\n",
    "    <value>org.apache.hadoop.mapred.ShuffleHandler</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.local-dirs</name>\n",
    "    <value>file:///opt/yarn/local</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.log-dirs</name>\n",
    "    <value>file:///opt/yarn/logs</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.resource.memory-mb</name>\n",
    "    <value>1536</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.scheduler.maximum-allocation-mb</name>\n",
    "    <value>1536</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.scheduler.minimum-allocation-mb</name>\n",
    "    <value>128</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.vmem-check-enabled</name>\n",
    "    <value>false</value>\n",
    "  </property>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "The following command updates the file automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T22:11:08.241162Z",
     "start_time": "2020-04-07T22:11:07.094038Z"
    }
   },
   "outputs": [],
   "source": [
    "!ssh hadoop@{NAMENODE_IP} 'printf \"%s\\n\" {commands.get_namenode_yarn_site(VMS[NAMENODE_IP])} > /opt/hadoop/etc/hadoop/yarn-site.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.** Update the `mapred-site.xml` file located at `/opt/hadoop/etc/hadoop` to configure the MAPREDUCE subsystem.\n",
    "The file must contain the following lines.\n",
    "```xml\n",
    "<configuration>\n",
    "  <property>\n",
    "    <name>mapreduce.framework.name</name>\n",
    "    <value>yarn</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>mapreduce.jobhistory.address</name>\n",
    "    <value>{namenode_hostname}:10020</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>mapreduce.jobhistory.webapp.address</name>\n",
    "    <value>{namenode_hostname}:19888</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>mapreduce.jobhistory.intermediate-done-dir</name>\n",
    "    <value>/mr-history/tmp</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>mapreduce.jobhistory.done-dir</name>\n",
    "    <value>/mr-history/done</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.app.mapreduce.am.env</name>\n",
    "    <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>mapreduce.map.env</name>\n",
    "    <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>mapreduce.reduce.env</name>\n",
    "    <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.app.mapreduce.am.resource.mb</name>\n",
    "    <value>512</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>mapreduce.map.memory.mb</name>\n",
    "    <value>256</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>mapreduce.reduce.memory.mb</name>\n",
    "    <value>256</value>\n",
    "  </property>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "The following command updates the file automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T22:11:10.387867Z",
     "start_time": "2020-04-07T22:11:09.326366Z"
    }
   },
   "outputs": [],
   "source": [
    "!ssh hadoop@{NAMENODE_IP} 'printf \"%s\\n\" {commands.get_namenode_mapred_site(VMS[NAMENODE_IP])} > /opt/hadoop/etc/hadoop/mapred-site.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If your machines have more than 2 GB of RAM or if you are interested in the numbers we specified in the YARN and MAPRED configuration files, check the Appendix A on the [Hadoop Memory Allocaltion](#memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.** Update the `workers` file located in `/opt/hadoop/etc/hadoop` to define the MAPREDUCE workers.\n",
    "With our virtual machines listed [here](#prereq), the file must contain the following lines.\n",
    "```\n",
    "172.16.0.225\n",
    "172.16.0.221\n",
    "172.16.0.224\n",
    "```\n",
    "The following command updates the file automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T22:17:40.521472Z",
     "start_time": "2020-04-07T22:17:39.217530Z"
    }
   },
   "outputs": [],
   "source": [
    "!ssh hadoop@{NAMENODE_IP} 'printf \"%s\\n\" {commands.get_workers(VMS)} > /opt/hadoop/etc/hadoop/workers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure the `hadoop-datanode` machines <a name=\"datanode\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.** Update the `core-site.xml` file located at `/opt/hadoop/etc/hadoop/` to define the name node URI on thie other datanodes.\n",
    "The file must contain the following lines.\n",
    "```xml\n",
    "<configuration>\n",
    "  <property>\n",
    "    <name>fs.defaultFS</name>\n",
    "    <value>hdfs://hadoop-namenode:9820/</value>\n",
    "  </property>\n",
    "</configuration>\n",
    "```\n",
    "The following command updates the file automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for host in REMAINING_IPS:\n",
    "    !ssh hadoop@{host} 'printf \"%s\\n\" {commands.get_datanode_core_site(VMS[NAMENODE_IP])} > /opt/hadoop/etc/hadoop/core-site.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** Update the `hdfs-site.xml` file located at `/opt/hadoop/etc/hadoop/` to configure the HDFS subsystem.\n",
    "The file must contain the following lines.\n",
    "```xml\n",
    "<configuration>\n",
    "  <property>\n",
    "    <name>dfs.datanode.data.dir</name>\n",
    "    <value>file:///opt/hdfs/datanode</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>dfs.replication</name>\n",
    "    <value>2</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>dfs.permissions</name>\n",
    "    <value>false</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>dfs.datanode.use.datanode.hostname</name>\n",
    "    <value>false</value>\n",
    "  </property>\n",
    "</configuration>\n",
    "```\n",
    "The following command updates the file automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for host in REMAINING_IPS:\n",
    "    !ssh hadoop@{host} 'printf \"%s\\n\" {commands.get_datanode_hdfs_site()} > /opt/hadoop/etc/hadoop/hdfs-site.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** Update the `yarn-site.xml` file located at `/opt/hadoop/etc/hadoop` to configure the YARN subsystem.\n",
    "The file must contain the following lines.\n",
    "```xml\n",
    "<configuration>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.aux-services</name>\n",
    "    <value>mapreduce_shuffle</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.resourcemanager.hostname</name>\n",
    "    <value>{namenode_hostname}</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.resource.memory-mb</name>\n",
    "    <value>1536</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.scheduler.maximum-allocation-mb</name>\n",
    "    <value>1536</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.scheduler.minimum-allocation-mb</name>\n",
    "    <value>128</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.vmem-check-enabled</name>\n",
    "    <value>false</value>\n",
    "  </property>\n",
    "</configuration>\n",
    "```\n",
    "The following command updates the file automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for host in REMAINING_IPS:\n",
    "    !ssh hadoop@{host} 'printf \"%s\\n\" {commands.get_datanode_yarn_site(VMS[NAMENODE_IP])} > /opt/hadoop/etc/hadoop/yarn-site.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.** Update the `mapred-site.xml` file located at `/opt/hadoop/etc/hadoop` to configure the MAPREDUCE subsystem.\n",
    "The file must contain the following lines.\n",
    "```xml\n",
    "<configuration>\n",
    "  <property>\n",
    "    <name>mapreduce.framework.name</name>\n",
    "    <value>yarn</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.app.mapreduce.am.env</name>\n",
    "    <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>mapreduce.map.env</name>\n",
    "    <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>mapreduce.reduce.env</name>\n",
    "    <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.app.mapreduce.am.resource.mb</name>\n",
    "    <value>512</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>mapreduce.map.memory.mb</name>\n",
    "    <value>256</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>mapreduce.reduce.memory.mb</name>\n",
    "    <value>256</value>\n",
    "  </property>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "The following command updates the file automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for host in REMAINING_IPS:\n",
    "    !ssh hadoop@{host} 'printf \"%s\\n\" {commands.get_datanode_mapred_site()} > /opt/hadoop/etc/hadoop/mapred-site.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If your machines have more than 2 GB of RAM or if you are interested in the numbers we specified in the YARN and MAPRED configuration files, check the Append A on the [Hadoop Memory Allocaltion](#memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a summary, please double check the content of the files list in the following picture, on the cluster machines:\n",
    "\n",
    "![Hadoop Configuration Files](hadoop_conf.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start, test and stop Hadoop <a name=\"test\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From now, all commands will be issued from the `hadoop-namenode` virtual machine.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a**. Delete the contents of the local HDFS file system.\n",
    "Note: **This causes the loss of all information stored in HDFS**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for host in VMS:\n",
    "    run_ssh(host, 'rm -rf /opt/hdfs/namenode/*')\n",
    "    run_ssh(host, 'rm -rf /opt/hdfs/datanode/*')\n",
    "    \n",
    "host = NAMENODE_IP\n",
    "!ssh hadoop@{host} 'stop-dfs.sh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b**. Format the HDFS filesystem at the namenode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = NAMENODE_IP\n",
    "!ssh hadoop@{host} 'hdfs namenode -format -force'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c**. Creating the HDFS home folder for the `hadoop` user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ssh hadoop@{host} 'start-dfs.sh'\n",
    "!ssh hadoop@{host} 'hadoop fs -mkdir -p /user/hadoop'\n",
    "!ssh hadoop@{host} 'stop-dfs.sh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d**. Starting HDFS and YARN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "host = NAMENODE_IP\n",
    "!ssh hadoop@{host} 'start-dfs.sh'\n",
    "!ssh hadoop@{host} 'start-yarn.sh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e**. Checking all daemons up and running. You should receive 5 lines from the namenode machine and 3 lines from the datanote machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for host in VMS:\n",
    "    run_ssh(host, 'jps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may check logs at `/opt/hadoop/logs` on the 3 machines and check if everything is alright, or running the `hdfs dfsadmin -report` command (it must return `Live datanodes (3)`).\n",
    "\n",
    "You can access Hadoop on a browser on your local machine (use IP addresses, not hostnames):\n",
    "- HDFS subsystem: `http://172.16.3.81:9870/`\n",
    "- YARN subsystem: `http://172.16.3.81:8088/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f.** Run an example provided by Hadoop.\n",
    "* Wait a minute before running, the daemons should perform some initialization steps\n",
    "* Ignore initial errors `No such file or directory`\n",
    "* Ignore logger message by logger `sasl.SaslDataTransferClient`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "host = NAMENODE_IP\n",
    "!ssh hadoop@{host} 'hadoop fs -rm -r input output'\n",
    "!ssh hadoop@{host} 'hadoop fs -put /opt/hadoop/etc/hadoop/ input'\n",
    "!ssh hadoop@{host} \"hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar grep /user/hadoop/input/*.xml /user/hadoop/output 'dfs[a-z.]+'\"\n",
    "!ssh hadoop@{host} 'hadoop fs -cat output/part-r-00000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g.** Stop HDFS and YARN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = NAMENODE_IP\n",
    "!ssh hadoop@{host} 'stop-dfs.sh'\n",
    "!ssh hadoop@{host} 'stop-yarn.sh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "If you get an error like the following:\n",
    "```bash\n",
    "[2020-01-14 08:48:28.567]Container [pid=155967,containerID=container_1578991625193_0002_01_000023] is running 380426752B beyond the 'VIRTUAL' memory limit. Current usage: 151.6 MB of 1 GB physical memory used; 2.5 GB of 2.1 GB virtual memory used. Killing container.\n",
    "```\n",
    "you are using more virtual memory than your current limit of 2.1 Gb. This can be resolved in two ways:\n",
    "\n",
    "  1. **Disable Virtual Memory Limit Checking**<br>YARN will simply ignore the limit; in order to do this, add this to your `yarn-site.xml` _on each machine_:\n",
    "      ```bash\n",
    "      <property>\n",
    "        <name>yarn.nodemanager.vmem-check-enabled</name>\n",
    "        <value>false</value>\n",
    "      </property>\n",
    "      ```\n",
    "      The default for this setting is `true`.\n",
    "\n",
    "  2. **Increase Virtual Memory to Physical Memory Ratio**<br>In your `yarn-site.xml` change this to a higher value than is currently set, _on each machine_:\n",
    "      ```bash\n",
    "      <property>\n",
    "        <name>yarn.nodemanager.vmem-pmem-ratio</name>\n",
    "        <value>5</value>\n",
    "      </property>\n",
    "      ```\n",
    "      The default is 2.1.<br>\n",
    "      You could also increase the amount of physical memory you allocate to a container.<br>\n",
    "      _Make sure you don't forget to restart yarn after you change the configuration_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A. Understanding the Hadoop Memory Allocation <a name=\"memory\"/>\n",
    "\n",
    "Memory allocation can be complex on low RAM nodes because default values are not suitable for nodes with less than 8 GB of RAM.\n",
    "In this section we highlight how memory allocation works for MapReduce jobs, and provide a sample configuration for 2 GB RAM nodes.\n",
    "\n",
    "A YARN job is executed with two kind of resources:\n",
    "\n",
    "* An **application master** (AM), which is responsible for monitoring the application and coordinating distributed executors in the cluster.\n",
    "* Some **executors**, that are created by the AM to actually run the job. For a MapReduce job, they will perform map or reduce operation, in parallel.\n",
    "\n",
    "Both are run in **containers** on **worker nodes**. Each worker node runs a **NodeManager** daemon that is responsible for container creation on the node.\n",
    "The whole cluster is managed by a **ResourceManager** that schedules container allocation on all the worker nodes, depending on capacity requirements and current charge.\n",
    "\n",
    "Four types of resource allocations need to be configured properly for the cluster to work. These are:\n",
    "\n",
    "1. _How much memory can be allocated for YARN containers on a single node._   This limit should be higher than all the others; otherwise, container allocation will be rejected and applications will fail. However, it should not be the entire amount of RAM on the node.\n",
    "This value is configured in the `yarn-site.xml` file with the `yarn.nodemanager.resource.memory-mb` property.\n",
    "\n",
    "2. _How much memory a single container can consume and the minimum memory allocation allowed._\n",
    "A container will never be bigger than the maximum, or else allocation will fail and will always be allocated as a multiple of the minimum amount of RAM.\n",
    "Those values are configured in the `yarn-site.xml` file with the `yarn.scheduler.maximum-allocation-mb` and `yarn.scheduler.minimum-allocation-mb` properties.\n",
    "\n",
    "3. _How much memory will be allocated to the ApplicationMaster._\n",
    "This is a constant value that should fit in the container maximum size.\n",
    "This value is configured in the `mapred-site.xml` with the `yarn.app.mapreduce.am.resource.mb` property.\n",
    "\n",
    "4. _How much memory will be allocated to each map or reduce operation._\n",
    "This should be less than the maximum size.\n",
    "This value is configured in the `mapred-site.xml` file with the `mapreduce.map.memory.mb` and `mapreduce.reduce.memory.mb` properties.\n",
    "\n",
    "The relationship between all those properties can be seen in the following figure:\n",
    "![](hadoop-2-memory-allocation.png)\n",
    "\n",
    "For 2 GB nodes, a working configuration may be:\n",
    "\n",
    "|Property|Value|\n",
    "|:-------|:----|\n",
    "|`yarn.nodemanager.resource.memory-mb`  | 1536|\n",
    "|`yarn.scheduler.maximum-allocation-mb` | 1536|\n",
    "|`yarn.scheduler.minimum-allocation-mb` |  128|\n",
    "|`yarn.app.mapreduce.am.resource.mb`    |  512|\n",
    "|`mapreduce.map.memory.mb`              |  256|\n",
    "|`mapreduce.reduce.memory.mb`           |  256|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
